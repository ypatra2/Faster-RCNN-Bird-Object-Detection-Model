import torch
import torchvision
import seaborn as sns
import matplotlib.pyplot as plt
import os
import numpy as np

from PIL import Image, ImageDraw

import pandas as pd

def overlapping_area(detection_1, detection_2):
    '''
    Function to calculate overlapping area'si
    `detection_1` and `detection_2` are 2 detections whose area
    of overlap needs to be found out.
    Each detection is list in the format ->
    [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]
    The function returns a value between 0 and 1,
    which represents the area of overlap.
    0 is no overlap and 1 is complete overlap.
    Area calculated from ->
    http://math.stackexchange.com/questions/99565/simplest-way-to-calculate-the-intersect-area-of-two-rectangles
    '''
    # Calculate the x-y co-ordinates of the 
    # rectangles
    x1_tl = detection_1[0]
    x2_tl = detection_2[0]
    x1_br = detection_1[0] + detection_1[3]
    x2_br = detection_2[0] + detection_2[3]
    y1_tl = detection_1[1]
    y2_tl = detection_2[1]
    y1_br = detection_1[1] + detection_1[4]
    y2_br = detection_2[1] + detection_2[4]
    # Calculate the overlapping Area
    x_overlap = max(0, min(x1_br, x2_br)-max(x1_tl, x2_tl))
    y_overlap = max(0, min(y1_br, y2_br)-max(y1_tl, y2_tl))
    overlap_area = x_overlap * y_overlap
    area_1 = detection_1[3] * detection_2[4]
    area_2 = detection_2[3] * detection_2[4]
    total_area = area_1 + area_2 - overlap_area
    return overlap_area / float(total_area)

def nms(detections, threshold=.9):
    '''
    This function performs Non-Maxima Suppression.
    `detections` consists of a list of detections.
    Each detection is in the format ->
    [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]
    If the area of overlap is greater than the `threshold`,
    the area with the lower confidence score is removed.
    The output is a list of detections.
    '''
    if len(detections) == 0:
        return []
    # Sort the detections based on confidence score
    detections = sorted(detections, key=lambda detections: detections[2],
            reverse=True)
    # Unique detections will be appended to this list
    new_detections=[]
    # Append the first detection
    new_detections.append(detections[0])
    # Remove the detection from the original list
    del detections[0]
    # For each detection, calculate the overlapping area
    # and if area of overlap is less than the threshold set
    # for the detections in `new_detections`, append the 
    # detection to `new_detections`.
    # In either case, remove the detection from `detections` list.
    for index, detection in enumerate(detections):
        for new_detection in new_detections:
            if overlapping_area(detection, new_detection) > threshold:
                del detections[index]
                break
        else:
            new_detections.append(detection)
            del detections[index]
    return new_detections


## Faster RCNN model loaded from torchvision
model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(
    pretrained=True, progress=True, num_classes=91, pretrained_backbone=True)

img_src = "/Users/u.v._ray/Documents/Python-testing/Data2/Test/images/"
save_dir = "/Users/u.v._ray/Documents/Python-testing/EE4211_RCNN_Practice/Test_gen_boxes_fasterrcnn_mobilenet_v3_large_fpn"

save_csv = "/Users/u.v._ray/Documents/Python-testing/EE4211_RCNN_Practice"

if not os.path.exists(save_dir):
    os.makedirs(save_dir)

df = pd.read_csv("/Users/u.v._ray/Documents/Python-testing/Data2/train_boundingboxes.csv")

Xmin_list = []
Ymin_list = []
Xmax_list = []
Ymax_list = []
string_list = []
counter = 0
for fname in sorted(os.listdir(img_src)):

    string_list.append(fname)
    image_path = os.path.join(img_src,fname)
    sample_image = Image.open(image_path)
    
    ## Using the RCNN Model on the transformed image to obtain result
    model.eval()

    #Using RGB conversion to convert image pixel-wise into a numpy array
    np_sample_image = np.array(sample_image.convert("RGB"))

    #Converting the numpy array to a tensor
    transformed_img = torchvision.transforms.transforms.ToTensor()(
        torchvision.transforms.ToPILImage()(np_sample_image))

    result = model([transformed_img])
    
    ## Using the result generated by the Faster RCNN Model (Pretrained Faster RCNN MobileNetv3 large FPN) to obtain the predicted boxes
    box_data = []
    labels_data = []
    scores_data = []
    for i in result[0]['boxes']:
        box_data.append(i.tolist())
    for i in result[0]['labels']:
        labels_data.append(i.tolist())
    for i in result[0]['scores']:
        scores_data.append(i.tolist())
        
    df_res = pd.DataFrame()

    df_res['boxes'] = box_data
    df_res['labels'] = labels_data
    df_res['scores'] = scores_data
        
    if len(df_res.loc[df_res['labels'] == 16]) > 0:
        
    
        df_res = df_res.loc[df_res['labels'] == 16]
        
        ## NMS on detections
        
        detections = []
        for idx, row in df_res.iterrows():
            
            temp_list = [row['boxes'][0], row['boxes'][1]]
            temp_list.append(row['scores']) #confidence score
            temp_list.append(row['boxes'][2] - row['boxes'][0]) ## Xmax - Xmin for width
            temp_list.append(row['boxes'][3] - row['boxes'][1]) ## Ymax - Ymin for width
            detections.append(temp_list)
        
        new_detections = nms(detections, threshold=.5)[0]
        
        Xmin, Ymin, Xmax, Ymax = new_detections[0], new_detections[1], new_detections[0] + new_detections[3], new_detections[1] + new_detections[4]
    
    elif len(df_res.loc[df_res['labels'] == 16]) == 0:
        
        df_res = df_res.loc[df_res['scores'] == max(df_res['scores'])]
        Xmin, Ymin, Xmax, Ymax = df_res['boxes'][0][0], df_res['boxes'][0][1], df_res['boxes'][0][2], df_res['boxes'][0][3]
        print(counter)
        counter += 1
        
    
    Xmin_list.append(Xmin)
    Ymin_list.append(Ymin)
    Xmax_list.append(Xmax)
    Ymax_list.append(Ymax)
    
    
    #Draw the bounded boxes to validate the object detection model
    sample_image_annotated = sample_image.copy()

    img_bbox = ImageDraw.Draw(sample_image_annotated)

    img_bbox.rectangle([Xmin, Ymin, Xmax, Ymax], outline="red")
    
    sample_image_annotated.save(os.path.join(save_dir,fname))
    
    
#Creating a DataFrame and storing the values of Xmin, Ymin, Xmax and Ymax into a .csv file
df_new = pd.DataFrame()
    
df_new['ImageId'] = string_list
df_new[' X_min'] = np.array(Xmin_list, dtype=np.int64)
df_new[' Y_min'] = np.array(Ymin_list, dtype=np.int64)
df_new[' X_max'] = np.array(Xmax_list, dtype=np.int64)
df_new[' Y_max'] = np.array(Ymax_list, dtype=np.int64)
df_new.set_index('ImageId', inplace=True)
df_new.to_csv("/Users/u.v._ray/Documents/Python-testing/EE4211_RCNN_Practice/Submission0_fasterrcnn_mobilenet_v3_large_fpn.csv")